{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02b3ed62",
   "metadata": {},
   "source": [
    "https://www.geeksforgeeks.org/deep-learning/training-neural-networks-using-pytorch-lightning/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33688673",
   "metadata": {},
   "source": [
    "PyTorch Lightning is a library that provides a high-level interface for PyTorch. Problem with PyTorch is that every time you start a project you have to rewrite those training and testing loop. PyTorch Lightning fixes the problem by not only reducing boilerplate code but also providing added functionality that might come handy while training your neural networks. One of the things I love about Lightning is that the code is very organized and reusable, and not only that but it reduces the training and testing loop while retain the flexibility that PyTorch is known for. And once you learn how to use it you'll see how similar the code is to that of PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73d34063",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import SGD\n",
    "\n",
    "import lightning.pytorch as lpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06b94216",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_path = \"../assets\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e99c783f",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "train = datasets.MNIST(mnist_path, train=True, download=True, transform=transform)\n",
    "test = datasets.MNIST(mnist_path, train=False, download=True, transform=transform)\n",
    "\n",
    "trainloader = DataLoader(train, batch_size=32, shuffle=True)\n",
    "testloader = DataLoader(test, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "906607fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data(lpt.LightningDataModule):\n",
    "    def prepare_data(self):\n",
    "        transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "        self.train_data = datasets.MNIST(\n",
    "            mnist_path, train=True, download=True, transform=transform\n",
    "        )\n",
    "        self.test_data = datasets.MNIST(\n",
    "            mnist_path, train=False, download=True, transform=transform\n",
    "        )\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_data, batch_size=32, shuffle=True)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.test_data, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "68d56f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "class model(lpt.LightningModule):\n",
    "    def __init__(self):\n",
    "        super(model, self).__init__()\n",
    "        self.fc1 = nn.Linear(28 * 28, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.out = nn.Linear(128, 10)\n",
    "        self.lr = 0.01\n",
    "        self.loss = nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, _, _, _ = x.size()\n",
    "        x = x.view(batch_size, -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        return self.out(x)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return SGD(self.parameters(), lr=self.lr)\n",
    "\n",
    "    def training_step(self, train_batch, batch_idx):\n",
    "        x, y = train_batch\n",
    "        logits = self.forward(x)\n",
    "        loss = self.loss(logits, y)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, valid_batch, batch_idx):\n",
    "        x, y = valid_batch\n",
    "        logits = self.forward(x)\n",
    "        loss = self.loss(logits, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9ec940b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ðŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "/home/volody/code/study-py/ts-pytorch/.venv/lib/python3.13/site-packages/lightning/pytorch/trainer/connectors/logger_connector/logger_connector.py:76: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `lightning.pytorch` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 5060 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name | Type             | Params | Mode  | FLOPs\n",
      "----------------------------------------------------------\n",
      "0 | fc1  | Linear           | 200 K  | train | 0    \n",
      "1 | fc2  | Linear           | 32.9 K | train | 0    \n",
      "2 | out  | Linear           | 1.3 K  | train | 0    \n",
      "3 | loss | CrossEntropyLoss | 0      | train | 0    \n",
      "----------------------------------------------------------\n",
      "235 K     Trainable params\n",
      "0         Non-trainable params\n",
      "235 K     Total params\n",
      "0.941     Total estimated model params size (MB)\n",
      "4         Modules in train mode\n",
      "0         Modules in eval mode\n",
      "0         Total Flops\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9cada07a4944099b8593a060428c645",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/volody/code/study-py/ts-pytorch/.venv/lib/python3.13/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:485: Your `val_dataloader`'s sampler has shuffling enabled, it is strongly recommended that you turn shuffling off for val/test dataloaders.\n",
      "/home/volody/code/study-py/ts-pytorch/.venv/lib/python3.13/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:434: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "/home/volody/code/study-py/ts-pytorch/.venv/lib/python3.13/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:434: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d44b46d1dd3643f3a351cbed52598b8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc21c2c7d1a3466980389ade7f6df2eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "354d7eb393804c0cb9f939e06bf2daab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5493a40d3c2495ca2b7522d45b45a14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50ae8a4e755b4099aa37eccdea915c5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66c5a76ec67343a891e9fb5aca34b668",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    }
   ],
   "source": [
    "# Create Model Object\n",
    "clf = model()\n",
    "# Create Data Module Object\n",
    "mnist = Data()\n",
    "# Create Trainer Object\n",
    "trainer = lpt.Trainer(accelerator=\"gpu\", max_epochs=5)\n",
    "trainer.fit(clf, mnist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d993c513",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ts-pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
