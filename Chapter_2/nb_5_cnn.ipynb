{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68a73f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17933db7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConvNet(\n",
      "  (conv1): Conv1d(5, 20, kernel_size=(3,), stride=(1,))\n",
      "  (fc): Linear(in_features=160, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, kernel_size, seq_length):\n",
    "        super(ConvNet, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv1d(input_size, hidden_size, kernel_size)\n",
    "        self.fc = nn.Linear(hidden_size * (seq_length - kernel_size + 1), output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.transpose(1, 2)  # swap sequence and feature dimensions\n",
    "        out = torch.relu(self.conv1(x))\n",
    "        out = out.view(out.size(0), -1)  # flatten the tensor\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "# 5 input channels, 20 output channels, 1 output feature, kernel size 3, sequence length 10\n",
    "convnet = ConvNet(5, 20, 1, 3, 10)\n",
    "print(convnet)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "721fa00e",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 10\n",
    "time_steps = 10\n",
    "features = 5\n",
    "output_size = 1\n",
    "\n",
    "X = torch.randn(100, time_steps, features)  # 100 samples, 5 time steps, 10 features\n",
    "Y = torch.randn(100, output_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f8bc709f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 1.2420650720596313\n",
      "Epoch 2, Loss: 1.2043087482452393\n",
      "Epoch 3, Loss: 1.1764110326766968\n",
      "Epoch 4, Loss: 1.1549708843231201\n",
      "Epoch 5, Loss: 1.1377930641174316\n",
      "Epoch 6, Loss: 1.1234616041183472\n",
      "Epoch 7, Loss: 1.1110502481460571\n",
      "Epoch 8, Loss: 1.0999606847763062\n",
      "Epoch 9, Loss: 1.0897915363311768\n",
      "Epoch 10, Loss: 1.080287218093872\n",
      "Epoch 11, Loss: 1.071277141571045\n",
      "Epoch 12, Loss: 1.0626393556594849\n",
      "Epoch 13, Loss: 1.054304838180542\n",
      "Epoch 14, Loss: 1.0462219715118408\n",
      "Epoch 15, Loss: 1.038353443145752\n",
      "Epoch 16, Loss: 1.030672550201416\n",
      "Epoch 17, Loss: 1.023161768913269\n",
      "Epoch 18, Loss: 1.0158079862594604\n",
      "Epoch 19, Loss: 1.0086009502410889\n",
      "Epoch 20, Loss: 1.0015274286270142\n",
      "Epoch 21, Loss: 0.9945788383483887\n",
      "Epoch 22, Loss: 0.9877555966377258\n",
      "Epoch 23, Loss: 0.9810516834259033\n",
      "Epoch 24, Loss: 0.9744644165039062\n",
      "Epoch 25, Loss: 0.9679908752441406\n",
      "Epoch 26, Loss: 0.9616209268569946\n",
      "Epoch 27, Loss: 0.9553530216217041\n",
      "Epoch 28, Loss: 0.9491832256317139\n",
      "Epoch 29, Loss: 0.9431062936782837\n",
      "Epoch 30, Loss: 0.9371194243431091\n",
      "Epoch 31, Loss: 0.9312307834625244\n",
      "Epoch 32, Loss: 0.9254226684570312\n",
      "Epoch 33, Loss: 0.9196974039077759\n",
      "Epoch 34, Loss: 0.9140496253967285\n",
      "Epoch 35, Loss: 0.9084819555282593\n",
      "Epoch 36, Loss: 0.9029945135116577\n",
      "Epoch 37, Loss: 0.8975800275802612\n",
      "Epoch 38, Loss: 0.8922370076179504\n",
      "Epoch 39, Loss: 0.886969804763794\n",
      "Epoch 40, Loss: 0.8817694783210754\n",
      "Epoch 41, Loss: 0.8766322135925293\n",
      "Epoch 42, Loss: 0.8715536594390869\n",
      "Epoch 43, Loss: 0.8665328025817871\n",
      "Epoch 44, Loss: 0.8615754842758179\n",
      "Epoch 45, Loss: 0.8566716909408569\n",
      "Epoch 46, Loss: 0.8518248200416565\n",
      "Epoch 47, Loss: 0.8470343947410583\n",
      "Epoch 48, Loss: 0.8422966003417969\n",
      "Epoch 49, Loss: 0.8376124501228333\n",
      "Epoch 50, Loss: 0.8329797387123108\n",
      "Epoch 51, Loss: 0.8283974528312683\n",
      "Epoch 52, Loss: 0.82387375831604\n",
      "Epoch 53, Loss: 0.8194010853767395\n",
      "Epoch 54, Loss: 0.8149721026420593\n",
      "Epoch 55, Loss: 0.8105880618095398\n",
      "Epoch 56, Loss: 0.8062513470649719\n",
      "Epoch 57, Loss: 0.8019599914550781\n",
      "Epoch 58, Loss: 0.7977126240730286\n",
      "Epoch 59, Loss: 0.7935121059417725\n",
      "Epoch 60, Loss: 0.7893557548522949\n",
      "Epoch 61, Loss: 0.7852427959442139\n",
      "Epoch 62, Loss: 0.7811700701713562\n",
      "Epoch 63, Loss: 0.7771358489990234\n",
      "Epoch 64, Loss: 0.7731387615203857\n",
      "Epoch 65, Loss: 0.7691791653633118\n",
      "Epoch 66, Loss: 0.7652565836906433\n",
      "Epoch 67, Loss: 0.7613716125488281\n",
      "Epoch 68, Loss: 0.7575149536132812\n",
      "Epoch 69, Loss: 0.7536959648132324\n",
      "Epoch 70, Loss: 0.7499125599861145\n",
      "Epoch 71, Loss: 0.7461632490158081\n",
      "Epoch 72, Loss: 0.7424477338790894\n",
      "Epoch 73, Loss: 0.7387649416923523\n",
      "Epoch 74, Loss: 0.7351033687591553\n",
      "Epoch 75, Loss: 0.7314738631248474\n",
      "Epoch 76, Loss: 0.7278750538825989\n",
      "Epoch 77, Loss: 0.7243000864982605\n",
      "Epoch 78, Loss: 0.7207551598548889\n",
      "Epoch 79, Loss: 0.7172315120697021\n",
      "Epoch 80, Loss: 0.7137365937232971\n",
      "Epoch 81, Loss: 0.7102720737457275\n",
      "Epoch 82, Loss: 0.7068302035331726\n",
      "Epoch 83, Loss: 0.7034168839454651\n",
      "Epoch 84, Loss: 0.700033962726593\n",
      "Epoch 85, Loss: 0.6966696381568909\n",
      "Epoch 86, Loss: 0.693329393863678\n",
      "Epoch 87, Loss: 0.6900125741958618\n",
      "Epoch 88, Loss: 0.686718761920929\n",
      "Epoch 89, Loss: 0.6834449768066406\n",
      "Epoch 90, Loss: 0.6801921725273132\n",
      "Epoch 91, Loss: 0.6769618391990662\n",
      "Epoch 92, Loss: 0.6737521886825562\n",
      "Epoch 93, Loss: 0.6705672740936279\n",
      "Epoch 94, Loss: 0.667405366897583\n",
      "Epoch 95, Loss: 0.6642634868621826\n",
      "Epoch 96, Loss: 0.6611437797546387\n",
      "Epoch 97, Loss: 0.6580457091331482\n",
      "Epoch 98, Loss: 0.6549696922302246\n",
      "Epoch 99, Loss: 0.6519132852554321\n",
      "Epoch 100, Loss: 0.64887535572052\n"
     ]
    }
   ],
   "source": [
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(convnet.parameters(), lr=0.01)\n",
    "\n",
    "for epoch in range(100):\n",
    "    output = convnet(X)\n",
    "    loss = loss_fn(output, Y)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}, Loss: {loss.item()}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ts-pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
